{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords, treebank\n",
    "\n",
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "import numpy.random as rand\n",
    "\n",
    "import string, re, json, socket, sys, os, h5py, nltk,csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f =open('/home/sol/CLUSTER_RAID/Tweets/2016MayTue17-144454.json','r')\n",
    "tweets=[]\n",
    "trash=[]\n",
    "for line in f.readlines():\n",
    "    if len(line) > 9:\n",
    "        tweets.append(line)\n",
    "    else:\n",
    "        trash.append(line)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time ='Mon May 16 02:33:57 +0000 2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mon', 'May', '16', '02:33:57', '+0000', '2016']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "general = ['gw', 'le', 'lo', 'll', 'lm', 'li', 'tn', 'tl', 'ls', 'th', \n",
    "           \n",
    "           'ti', 'te', 'do', 'dj', 'yo', 'ya', 'dg', 'yb', 'da', 'dy', \n",
    "           \n",
    "           'uy', 'ys', 'ahaha', 'dp', 'pffttt', 'l', 'btw', 'ea', 'et', \n",
    "           \n",
    "           'rt', 'ul', 'rf', 'rm', 'ro', 'rj', 'wd', 'omg', 'ba', 'wa', \n",
    "           \n",
    "           'ju', 'bn', 'wk', 'bi', 'wi', 'bk', 'wtf', 'bs', 'wy', 'om', \n",
    "           \n",
    "           'oa', 'uni', 'ck', 'vid', 'cl', 'xc', 'ca', 'cf', 'cr', 'pr', \n",
    "           \n",
    "           'pp', 'pa', 'pi', 'tk', 'hr', 'hi', 'ha', 'md', 'ma', 'ml', \n",
    "           \n",
    "           'mi', 'us', 'mt', 'mv', 'ms', 'mr', 'ue', 'ae', 'ad', 'ak', 'vn', \n",
    "           \n",
    "           'ay', 'vr', 'ar', 'ia', 'ie', 'ig', 'nb', 'ny', 'nt', 'fr', 'ft',\n",
    "           \n",
    "           'fu', 'fa', 'fd', 'fe', 'fi', 'fl', 'sfeh', 'ki', 'kn', 'sk', 'kp',\n",
    "           \n",
    "           'sn', 'sl', 'sf','nd', 'lk', 'gd']\n",
    "\n",
    "punctuation = list(string.punctuation)\n",
    "\n",
    "general_upper = [word.upper() for word in general]\n",
    "\n",
    "general_cap = [word.title() for word in general]\n",
    "\n",
    "stop = json.dumps(stopwords.words('english') )\n",
    "\n",
    "stop = stop.replace('[','').replace('\"','').replace(']','').replace(' ','')\n",
    "\n",
    "stop = stop.split(',')\n",
    "\n",
    "stop_upper = [word.upper() for word in stop]\n",
    "\n",
    "stop_cap = [word.title() for word in stop]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "letters = [letter for letter in \n",
    "           \n",
    "           string.ascii_lowercase + \n",
    "           \n",
    "           string.ascii_uppercase \n",
    "           \n",
    "           if letter not in \n",
    "           \n",
    "           ['a','A','I','i']]\n",
    "\n",
    "nums = []\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    nums.append(str(i))\n",
    "\n",
    "    nums.append(str(i/1e1))\n",
    "\n",
    "\n",
    "all_stops = general + general_upper + general_cap + letters + punctuation + stop + nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "\n",
    "    (?:\n",
    "\n",
    "        [:=;] # Eyes\n",
    "\n",
    "        [oO\\-]? # Nose (optional)\n",
    "\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "\n",
    "    )\"\"\"\n",
    "\n",
    "regex_str = [\n",
    "\n",
    "    emoticons_str,\n",
    "\n",
    "    r'<[^>]+>', # HTML tags\n",
    "\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    "\n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "\n",
    "    r'(?:\\S)' # anything else\n",
    "\n",
    "        ]\n",
    "\n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "\n",
    "def tokenize(s):\n",
    "    \n",
    "    return word_tokenize(s) \n",
    "\n",
    "def preprocess(s, lowercase=False):\n",
    "\n",
    "    tokens = tokenize(s)\n",
    "    \n",
    "    if lowercase:\n",
    "        \n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Clean_List_of_Sentence(sent_list):\n",
    "    \n",
    "    keepers = []\n",
    "    \n",
    "    for i in sent_list:\n",
    "\n",
    "        for j in i:\n",
    "            \n",
    "\n",
    "            if j in all_stops:\n",
    "\n",
    "                continue\n",
    "\n",
    "            for i in punctuation:\n",
    "\n",
    "                j.replace(i,'').replace(i+i,'').replace(i+i+i,'')\n",
    "\n",
    "            if j.startswith( ('#','@','http','//','/','~',':','\\\\n','\\\\')):\n",
    "\n",
    "                continue\n",
    "\n",
    "            if j.endswith( ('#','@','http','//','/','~',':','\\\\n','\\\\')):\n",
    "\n",
    "                continue\n",
    "\n",
    "            if j=='':\n",
    "\n",
    "                continue\n",
    "\n",
    "            marker=False\n",
    "            word = ''\n",
    "            word_len = len(j)\n",
    "            for k in j:\n",
    "\n",
    "                if j.lower().count(k.lower())>=word_len//2:\n",
    "                    \n",
    "                    continue\n",
    "            \n",
    "                    \n",
    "                if k in punctuation:\n",
    "                    \n",
    "                    continue\n",
    "\n",
    "                if k in nums:\n",
    "                    \n",
    "                    continue\n",
    "                \n",
    "                word+=k\n",
    "\n",
    "                marker=True\n",
    "\n",
    "            if word in all_stops:\n",
    "\n",
    "                continue\n",
    "\n",
    "            if marker==True: \n",
    "\n",
    "                keepers.append(word.lower())\n",
    "    \n",
    "    \n",
    "    return keepers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/sol/wordlist.txt','r') as f:\n",
    "    wordlist = [word.rstrip('\\r\\n') for word in  f.readlines()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69905\n"
     ]
    }
   ],
   "source": [
    "wordlist = [ word.replace('(p)','').replace('(a)','').replace('(ip)','') for word in wordlist]\n",
    "print len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'] \n",
      "\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~'] \n",
      "\n",
      "['gw', 'le', 'lo', 'll', 'lm', 'li', 'tn', 'tl', 'ls', 'th', 'ti', 'te', 'do', 'dj', 'yo', 'ya', 'dg', 'yb', 'da', 'dy', 'uy', 'ys', 'ahaha', 'dp', 'pffttt', 'l', 'btw', 'ea', 'et', 'rt', 'ul', 'rf', 'rm', 'ro', 'rj', 'wd', 'omg', 'ba', 'wa', 'ju', 'bn', 'wk', 'bi', 'wi', 'bk', 'wtf', 'bs', 'wy', 'om', 'oa', 'uni', 'ck', 'vid', 'cl', 'xc', 'ca', 'cf', 'cr', 'pr', 'pp', 'pa', 'pi', 'tk', 'hr', 'hi', 'ha', 'md', 'ma', 'ml', 'mi', 'us', 'mt', 'mv', 'ms', 'mr', 'ue', 'ae', 'ad', 'ak', 'vn', 'ay', 'vr', 'ar', 'ia', 'ie', 'ig', 'nb', 'ny', 'nt', 'fr', 'ft', 'fu', 'fa', 'fd', 'fe', 'fi', 'fl', 'sfeh', 'ki', 'kn', 'sk', 'kp', 'sn', 'sl', 'sf', 'nd', 'lk', 'gd'] \n",
      "\n",
      "['GW', 'LE', 'LO', 'LL', 'LM', 'LI', 'TN', 'TL', 'LS', 'TH', 'TI', 'TE', 'DO', 'DJ', 'YO', 'YA', 'DG', 'YB', 'DA', 'DY', 'UY', 'YS', 'AHAHA', 'DP', 'PFFTTT', 'L', 'BTW', 'EA', 'ET', 'RT', 'UL', 'RF', 'RM', 'RO', 'RJ', 'WD', 'OMG', 'BA', 'WA', 'JU', 'BN', 'WK', 'BI', 'WI', 'BK', 'WTF', 'BS', 'WY', 'OM', 'OA', 'UNI', 'CK', 'VID', 'CL', 'XC', 'CA', 'CF', 'CR', 'PR', 'PP', 'PA', 'PI', 'TK', 'HR', 'HI', 'HA', 'MD', 'MA', 'ML', 'MI', 'US', 'MT', 'MV', 'MS', 'MR', 'UE', 'AE', 'AD', 'AK', 'VN', 'AY', 'VR', 'AR', 'IA', 'IE', 'IG', 'NB', 'NY', 'NT', 'FR', 'FT', 'FU', 'FA', 'FD', 'FE', 'FI', 'FL', 'SFEH', 'KI', 'KN', 'SK', 'KP', 'SN', 'SL', 'SF', 'ND', 'LK', 'GD'] \n",
      "\n",
      "['Gw', 'Le', 'Lo', 'Ll', 'Lm', 'Li', 'Tn', 'Tl', 'Ls', 'Th', 'Ti', 'Te', 'Do', 'Dj', 'Yo', 'Ya', 'Dg', 'Yb', 'Da', 'Dy', 'Uy', 'Ys', 'Ahaha', 'Dp', 'Pffttt', 'L', 'Btw', 'Ea', 'Et', 'Rt', 'Ul', 'Rf', 'Rm', 'Ro', 'Rj', 'Wd', 'Omg', 'Ba', 'Wa', 'Ju', 'Bn', 'Wk', 'Bi', 'Wi', 'Bk', 'Wtf', 'Bs', 'Wy', 'Om', 'Oa', 'Uni', 'Ck', 'Vid', 'Cl', 'Xc', 'Ca', 'Cf', 'Cr', 'Pr', 'Pp', 'Pa', 'Pi', 'Tk', 'Hr', 'Hi', 'Ha', 'Md', 'Ma', 'Ml', 'Mi', 'Us', 'Mt', 'Mv', 'Ms', 'Mr', 'Ue', 'Ae', 'Ad', 'Ak', 'Vn', 'Ay', 'Vr', 'Ar', 'Ia', 'Ie', 'Ig', 'Nb', 'Ny', 'Nt', 'Fr', 'Ft', 'Fu', 'Fa', 'Fd', 'Fe', 'Fi', 'Fl', 'Sfeh', 'Ki', 'Kn', 'Sk', 'Kp', 'Sn', 'Sl', 'Sf', 'Nd', 'Lk', 'Gd'] \n",
      "\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'] \n",
      "\n",
      "['I', 'ME', 'MY', 'MYSELF', 'WE', 'OUR', 'OURS', 'OURSELVES', 'YOU', 'YOUR', 'YOURS', 'YOURSELF', 'YOURSELVES', 'HE', 'HIM', 'HIS', 'HIMSELF', 'SHE', 'HER', 'HERS', 'HERSELF', 'IT', 'ITS', 'ITSELF', 'THEY', 'THEM', 'THEIR', 'THEIRS', 'THEMSELVES', 'WHAT', 'WHICH', 'WHO', 'WHOM', 'THIS', 'THAT', 'THESE', 'THOSE', 'AM', 'IS', 'ARE', 'WAS', 'WERE', 'BE', 'BEEN', 'BEING', 'HAVE', 'HAS', 'HAD', 'HAVING', 'DO', 'DOES', 'DID', 'DOING', 'A', 'AN', 'THE', 'AND', 'BUT', 'IF', 'OR', 'BECAUSE', 'AS', 'UNTIL', 'WHILE', 'OF', 'AT', 'BY', 'FOR', 'WITH', 'ABOUT', 'AGAINST', 'BETWEEN', 'INTO', 'THROUGH', 'DURING', 'BEFORE', 'AFTER', 'ABOVE', 'BELOW', 'TO', 'FROM', 'UP', 'DOWN', 'IN', 'OUT', 'ON', 'OFF', 'OVER', 'UNDER', 'AGAIN', 'FURTHER', 'THEN', 'ONCE', 'HERE', 'THERE', 'WHEN', 'WHERE', 'WHY', 'HOW', 'ALL', 'ANY', 'BOTH', 'EACH', 'FEW', 'MORE', 'MOST', 'OTHER', 'SOME', 'SUCH', 'NO', 'NOR', 'NOT', 'ONLY', 'OWN', 'SAME', 'SO', 'THAN', 'TOO', 'VERY', 'S', 'T', 'CAN', 'WILL', 'JUST', 'DON', 'SHOULD', 'NOW', 'D', 'LL', 'M', 'O', 'RE', 'VE', 'Y', 'AIN', 'AREN', 'COULDN', 'DIDN', 'DOESN', 'HADN', 'HASN', 'HAVEN', 'ISN', 'MA', 'MIGHTN', 'MUSTN', 'NEEDN', 'SHAN', 'SHOULDN', 'WASN', 'WEREN', 'WON', 'WOULDN'] \n",
      "\n",
      "['I', 'Me', 'My', 'Myself', 'We', 'Our', 'Ours', 'Ourselves', 'You', 'Your', 'Yours', 'Yourself', 'Yourselves', 'He', 'Him', 'His', 'Himself', 'She', 'Her', 'Hers', 'Herself', 'It', 'Its', 'Itself', 'They', 'Them', 'Their', 'Theirs', 'Themselves', 'What', 'Which', 'Who', 'Whom', 'This', 'That', 'These', 'Those', 'Am', 'Is', 'Are', 'Was', 'Were', 'Be', 'Been', 'Being', 'Have', 'Has', 'Had', 'Having', 'Do', 'Does', 'Did', 'Doing', 'A', 'An', 'The', 'And', 'But', 'If', 'Or', 'Because', 'As', 'Until', 'While', 'Of', 'At', 'By', 'For', 'With', 'About', 'Against', 'Between', 'Into', 'Through', 'During', 'Before', 'After', 'Above', 'Below', 'To', 'From', 'Up', 'Down', 'In', 'Out', 'On', 'Off', 'Over', 'Under', 'Again', 'Further', 'Then', 'Once', 'Here', 'There', 'When', 'Where', 'Why', 'How', 'All', 'Any', 'Both', 'Each', 'Few', 'More', 'Most', 'Other', 'Some', 'Such', 'No', 'Nor', 'Not', 'Only', 'Own', 'Same', 'So', 'Than', 'Too', 'Very', 'S', 'T', 'Can', 'Will', 'Just', 'Don', 'Should', 'Now', 'D', 'Ll', 'M', 'O', 'Re', 'Ve', 'Y', 'Ain', 'Aren', 'Couldn', 'Didn', 'Doesn', 'Hadn', 'Hasn', 'Haven', 'Isn', 'Ma', 'Mightn', 'Mustn', 'Needn', 'Shan', 'Shouldn', 'Wasn', 'Weren', 'Won', 'Wouldn']\n"
     ]
    }
   ],
   "source": [
    "print letters,'\\n\\n',punctuation,'\\n\\n',general,'\\n\\n',general_upper,'\\n\\n',general_cap,'\\n\\n',stop,'\\n\\n',stop_upper,'\\n\\n',stop_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for letter in string.ascii_lowercase:\n",
    "    \n",
    "    with open('/home/sol/CLUSTER_RAID/Tweet_Code/Words_By_Alpha/'+letter,'wb') as f:\n",
    "        \n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        for word in wordlist:\n",
    "            \n",
    "            if word.startswith((letter.upper(),letter.lower())):\n",
    "                \n",
    "                writer.writerow([word])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462\n"
     ]
    }
   ],
   "source": [
    "sents = []\n",
    "for i in range(len(tweets)):\n",
    "    try:\n",
    "        sents.append(json.loads(tweets[i])['text'].encode('ascii', 'ignore'))\n",
    "    except:\n",
    "        continue\n",
    "print len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_set=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Why', 'females', 'be', 'lyin', 'on', 'twitter', 'talm', 'bout', 'if', 'they', 'had', 'a', 'relationship', 'but', 'when', 'a', 'man', 'that', 'is', 'actually', 'worth', 'it', 'and', 'they', 'like', 'come', 'they', 'scared', '?'], ['RT', '@', 'adryenn', ':', 'In', 'case', 'you', 'do', \"n't\", 'actually', 'understand', 'what', 'all', 'the', 'hullabaloo', 'is', 'about', '.', '#', 'TeamBernieNV', '#', 'FeelTheBern', '#', 'FreeThe64', 'https', ':', '//t.co/Zoq'], ['I', 'ALSO', 'HAVE', 'CHINESE', 'FOOD', '!', 'BLESS', 'THE', 'REALEST', 'BAE', 'OUT', '@', 'Eat24'], ['@', 'MattNerger', 'boul', 'looks', 'like', 'a', 'middle', 'school', 'music', 'teacher'], ['You', 'better', 'call', 'Becky', 'with', 'the', 'long', 'braids'], ['Should', 'I', 'get', 'a', 'part', 'in', 'my', 'hair', 'or', 'just', 'get', 'the', 'same', 'haircut', 'as', 'last', 'time', '?'], ['This', 'bitch', 'actin', 'like', 'she', 'did', \"n't\", 'know', 'she', 'was', 'bein', 'video', \"'d\", 'meanwhile', 'the', 'flash', 'was', 'glarin', 'in', 'her', 'face', 'https', ':', '//t.co/QYRnzlL7y8'], ['Do', 'not', 'even', 'waste', 'your', 'time', 'talking', 'to', 'me', 'if', 'you', 'smoke', 'cigarettes', '.'], ['lmao', 'melanin', '?', 'Dark', 'pigment', 'in', 'your', 'skin', 'that', 'absorbs', 'color', 'https', ':', '//t.co/QENEKKwyGE'], ['@', 'sureshpprabhu', 'only', 'passenger', 'of', 'rajdhani', 'express', 'pays', 'fair', 'so', 'only', 'Rajdhani', 'goes', 'and', 'all', 'train', 'stands', 'on', 'the', 'station', '.', 'Great', 'job']]\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    #rint sent\n",
    "    token_set.append(preprocess(sent))\n",
    "\n",
    "print token_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned =  Clean_List_of_Sentence(token_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['females', 'lyin', 'wier', 'talm', 'bout', 'relationship', 'actually', 'worth', 'like', 'come', 'scared', 'adryenn', 'case', 'actually', 'understand', 'hullabaloo', 'teambernienv', 'feelthebern', 'freethe', 'also', 'have', 'chinese', 'ble', 'realest', 'eat', 'mattnerger', 'boul', 'lks', 'like', 'middle', 'school', 'music', 'teacher', 'better', 'becky', 'long', 'braids', 'should', 'part', 'hair', 'haircut', 'last', 'time', 'this', 'bitch', 'actin', 'like', 'know', 'bein', 'video', 'meanwhile', 'flash', 'glarin', 'face', 'waste', 'time', 'talking', 'smoke', 'cigarettes', 'lmao', 'melanin', 'dark', 'pigment', 'skin', 'absorbs', 'clr', 'sureshpprabhu', 'passenger', 'rajdhani', 'express', 'pays', 'fair', 'rajdhani', 'goes', 'train', 'stands', 'station', 'great', 'elaine', 'uke', 'austria', 'july', 'traditional', 'chaletstyle', 'home', 'westsidekilla', 'wait', 'pick', 'kie', 'heycoty', 'thanks', 'follow', 'means', 'alot', 'constanzab', 'drmorton', 'quick', 'tips', 'about', 'wier', 'business', 'oca', 'entrepreneur', 'stared', 'remember', 'judging', 'eyebrows', 'looked', 'like', 'drew', 'curved', 'lines', 'forehead', 'jcub', 'this', 'predict', 'like', 'diets', 'delafro', 'hate', 'late', 'wier', 'bf', 'tweets', 'like', 'keeping', 'braids', 'next', 'couple', 'months', 'jessicaleethe', 'have', 'looked', 'someone', 'theyre', 'something', 'sma', 'like', 'driving', 'laughing', 'talking', 'smile', 'alanvaarwerk', 'turns', 'strip', 'pictures', 'buzzfeed', 'article', 'strangely', 'affecting', 'vrs', 'poem', 'become', 'increasingly', 'intuitive', 'unsteady', 'ruig', 'violently', 'when', 'comes', 'store', 'nonsensposts', 'when', 'salt', 'reach', 'stays', 'wke', 'forever', 'jayaababyy', 'sister', 'lay', 'everydayi', 'soy', 'could', 'therelove', 'victory', 'sma', 'victory', 'victory', 'nonetheless', 'nashgrier', 'back', 'next', 'time', 'hayesgrier', 'haykathryn', 'idea', 'individuals', 'experiencing', 'facing', 'behind', 'closed', 'doors', 'kind', 'people', 'deemahasan', 'thank', 'greatobsession', 'interested', 'amourerykah']\n"
     ]
    }
   ],
   "source": [
    "print cleaned[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(cleaned)\n",
    "count_all = Counter(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NN\n",
      "---\n",
      "NN <type 'int'>\n"
     ]
    }
   ],
   "source": [
    "for (word,key),value in count_all.most_common():\n",
    "    \n",
    "    print T[key]+value\n",
    "    \n",
    "    print key,type(value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = ['date','possessive pronoun', 'verb present participle or gerund',\n",
    "\n",
    "        'verb past tense', 'verb past participle', 'verb, present tense not 3rd person singular', \n",
    "\n",
    "        'WH-determiner','adjective or numeral, ordinal', 'WH-pronoun', \n",
    "\n",
    "        'verb present tense 3rd person singular','determiner', 'particle', \n",
    "\n",
    "        'noun, common, singular or mass', '\"to\" as preposition or infinitive marker',\n",
    "\n",
    "        'personal pronoun', 'adverb', 'common noun plural', ' proper noun singular',\n",
    "\n",
    "        'base form verb', 'Wh-adverb','coordinating conjunction', 'comparative adverb',\n",
    "\n",
    "        'cardinal numeral', 'No matching tags found', 'existential there there', \n",
    "\n",
    "        'subordinating preposition or conjunction','possessive WH-pronoun', \n",
    "\n",
    "        'modal auxiliary', 'superlative adjective', 'comparative adjective']\n",
    "\n",
    "names = ['PRP$', 'VBG', 'VBD', 'VBN', 'VBP', 'WDT',\n",
    "\n",
    "    'JJ', 'WP', 'VBZ', 'DT', 'RP', 'NN', 'TO',\n",
    "\n",
    "    'PRP', 'RB', 'NNS', 'NNP', 'VB', 'WRB',\n",
    "\n",
    "    'CC', 'RBR', 'CD', '-NONE-', 'EX', 'IN',\n",
    "\n",
    "    'WP$', 'MD', 'JJS', 'JJR' ]\n",
    "\n",
    "T = Table( names=names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T['NN'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "Record_book = {}\n",
    "\n",
    "Record_book.fromkeys(['PRP$', 'VBG', 'VBD', 'VBN', 'VBP', 'WDT',\n",
    "\n",
    "                        'JJ', 'WP', 'VBZ', 'DT', 'RP', 'NN', 'TO',\n",
    "\n",
    "                        'PRP', 'RB', 'NNS', 'NNP', 'VB', 'WRB',\n",
    "\n",
    "                        'CC', 'RBR', 'CD', '-NONE-', 'EX', 'IN',\n",
    "\n",
    "                        'WP$', 'MD', 'JJS', 'JJR' ] , 0 )\n",
    "print Record_book.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('strong', 'JJ'), ('courage', 'NN'), ('fear', 'NN'), ('lord', 'NN'), ('goes', 'VBZ'), ('deuteronomy', 'NN'), ('crazylifefacts', 'NNS'), ('laughed', 'VBD'), ('more', 'JJR'), ('than', 'IN'), ('should', 'MD'), ('have', 'VB'), ('jpav', 'NN'), ('reminder', 'NN'), ('forwardhockey', 'NN'), ('gave', 'VBD'), ('keys', 'NNS'), ('jpav', 'NN'), ('handle', 'NN'), ('night', 'NN'), ('awesome', 'NN'), ('stu', 'NN'), ('coming', 'VBG'), ('nhlpavels', 'NNS'), ('femalebook', 'VBP'), ('people', 'NNS'), ('drop', 'NN'), ('home', 'NN'), ('wait', 'NN'), ('actually', 'RB'), ('inside', 'VBP'), ('house', 'NN'), ('drive', 'NN'), ('beautiful', 'NN'), ('dsrv', 'NN'), ('newbergreport', 'NN'), ('usy', 'NN'), ('line', 'NN'), ('bth', 'NN'), ('rougie', 'NN'), ('five', 'CD'), ('great', 'JJ'), ('line', 'NN'), ('greywormgot', 'NN'), ('unsullied', 'VBD'), ('waiting', 'VBG'), ('islamicfreedom', 'NN'), ('fufi', 'NN'), ('dreams', 'NNS'), ('give', 'VBP')]\n"
     ]
    }
   ],
   "source": [
    "print tagged[:50]#tagged[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('like', 'IN'), 28), (('people', 'NNS'), 20), (('love', 'NN'), 17), (('would', 'MD'), 16), (('time', 'NN'), 14), (('really', 'RB'), 13), (('sti', 'NN'), 12), (('girl', 'NN'), 12), (('know', 'VB'), 10), (('hay', 'NN'), 10)]\n"
     ]
    }
   ],
   "source": [
    "print count_all.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wouldn JJR 28\n"
     ]
    }
   ],
   "source": [
    "for adjective,number in count_all.most_common(20):\n",
    "    print word,key,number\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "No matching tags found.\n",
      "EX: existential there\n",
      "    there\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n"
     ]
    }
   ],
   "source": [
    "list_ = ['PRP$', 'VBG', 'VBD', 'VBN', 'VBP', 'WDT', 'JJ', 'WP', 'VBZ', 'DT', 'RP', 'NN', 'TO', \n",
    "\n",
    "'PRP', 'RB', 'NNS', 'NNP', 'VB', 'WRB', 'CC', 'RBR', 'CD', '-NONE-', 'EX', 'IN', 'WP$', 'MD', 'JJS', 'JJR']\n",
    "for symbol in list_:\n",
    "    nltk.help.upenn_tagset(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word,key,number in count_all.most_common():\n",
    "    \n",
    "    with open(DICTIONARY_PATH+word[0],'r') as word_check:\n",
    "        \n",
    "        if not word in word_check.readlines():\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    d[key] += number\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/home/sol/CLUSTER_RAID/Tweet_Code/dictionary.txt','wb') as f:\n",
    "\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for key, val in type_dict.items():\n",
    "\n",
    "        writer.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_log.update(count_all.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_log = {}\n",
    "with open('/home/sol/CLUSTER_RAID/Tweet_Code/dictionary.txt','rb') as f:\n",
    "\n",
    "    for key,val in csv.reader(f):\n",
    "\n",
    "        word_log[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print word_log.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in word_log.keys():\n",
    "    \n",
    "    print key,len(word_log[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammer_book = {}\n",
    "date_book = {}\n",
    "word_book = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammer_book.fromkeys(['DATE_TIME','PRP$', 'VBG', 'VBD', 'VBN', 'VBP', 'WDT', \n",
    "            \n",
    "            'JJ', 'WP', 'VBZ', 'DT', 'RP', 'NN', 'TO', \n",
    "            \n",
    "            'PRP', 'RB', 'NNS', 'NNP', 'VB', 'WRB', 'CC', \n",
    "            \n",
    "            'RBR', 'CD', '-NONE-', 'EX', 'IN', 'WP$', 'MD', \n",
    "            \n",
    "            'JJS', 'JJR'] ,0\n",
    ")\n",
    "word_book = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.06763"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "type(localtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tdtype=(\n",
    "\n",
    "\t\t'f','uint32','uint32','uint32','uint32',\n",
    "\n",
    "\t\t'uint32','uint32','uint32','uint32','uint32',\n",
    "\n",
    "\t\t'uint32','uint32','uint32','uint32','uint32',\n",
    "\n",
    "\t\t'uint32','uint32','uint32','uint32','uint32'\n",
    "\n",
    "\t\t'uint32','uint32','uint32','uint32','uint32',\n",
    "\n",
    "\t\t'uint32','uint32','uint32','uint32','uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tnames=(\n",
    "\n",
    "\t\t'date','possessive pronoun', 'verb present participle or gerund',\n",
    "\n",
    "\t\t'verb past tense', 'verb past participle', 'verb, present tense not 3rd person singular', \n",
    "\n",
    "\t\t'WH-determiner','adjective or numeral, ordinal', 'WH-pronoun', \n",
    "\n",
    "\t\t'verb present tense 3rd person singular','determiner', 'particle', \n",
    "\n",
    "\t\t'noun, common, singular or mass', '\"to\" as preposition or infinitive marker',\n",
    "\n",
    "\t\t'personal pronoun', 'adverb', 'common noun plural', ' proper noun singular',\n",
    "\n",
    "\t\t'base form verb', 'Wh-adverb','coordinating conjunction', 'comparative adverb',\n",
    "\n",
    "\t\t'cardinal numeral', 'No matching tags found', 'existential there there', \n",
    "\n",
    "\t\t'subordinating preposition or conjunction','possessive WH-pronoun', \n",
    "\n",
    "\t\t'modal auxiliary', 'superlative adjective', 'comparative adjective')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
